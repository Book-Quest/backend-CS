# Q.  넷플릭스같은 서비스를 디자인하면 어떻게 할 것인가?

# 서비스의 기본 구조

<img width="728" alt="Pasted Graphic" src="https://github.com/user-attachments/assets/4216d3ae-c1cc-4a66-b2ca-12d186a2ac97" />


## 서비스에 접속하는 일련의 과정

1. URL 입력
2. DNS 응답
3. 사이트 접속
4. TCP/IP 접속이 이루어짐
5. 로그인 → 영상의 목록들이 나옴
6. 사용자가 영상선택
7. 재생 → 지연, 버퍼링을 고려, 영상 전송을 어떻게 할 것인가? (서버 전송 등)

## 반드시 고려해야 할 사항

### 최초 접속과 사용자 인증

- ID, PW로 인증 (지식 기반 인증)
- 중복접속은 어떻게 처리할 것인가? ⇒ IP + 기기 정보를 추가로 다뤄야 함

### 영상 목록 조회

### 영상 사용자 선택 및 재생 (다운로드 가능성)

- 재생을 하려면 Player가 필요
- HTML5 베이스로 사용 경우 Video.js를 사용해서 브라우저에서 자체 재생가능
- 따로 플레이어를 설치 하지 않아도 됨 (사용자는 편해짐)
- But 사용자가 영상을 다운로드 할 수 있음
- 다운로드를 허용할 것인가 말 것인가, 허용한다면 기간을 어느정도로 정할 것인가 (디지털 컨텐츠 저작권 보호 이슈)
    - DRM 솔루션을 적용시킬 것인가
    - 그렇다면 전용 플레이어를 다운 받아야 하는 것이 강제될 수 있음

### 전송 방법 (HTTP, HLS)

- 인코딩: h.264 코덱, mp4 ⇒ 브라우저에서 재생창이 뜸
    - 그러면 웹서버를 통해서 파일의 내용이 스트리밍 돼서 날아감
    - 그러지 않겠다고 하면 http를 이용해서 라이브로 스트림을 쏴줄 수 있는 스트리밍 서버를 따뤄 둬야 함
    - 그럼 이런 경우에는 코덱을 뭘로 가져와서 이런 시스템을 도입할 것인지 고민해야 함
- 전송은 웹서버가 담당
- 웹서버와 미디어를 전송해주는 스트리밍 서버를 같이 운영할 것인가에 대한 고민이 필요

---

### **1. 웹 서버 (Web Server)**

✅ **역할**: HTML, CSS, JavaScript, 이미지, 동영상 파일 등의 정적/동적 콘텐츠를 클라이언트(웹 브라우저)에게 제공

✅ **작동 방식**: HTTP 프로토콜을 사용해 요청(Request)을 받고, 응답(Response)으로 데이터를 반환

✅ **사용 예시**:

- 사용자가 브라우저에서 `www.example.com`에 접속하면, 웹 서버가 HTML 파일을 반환하여 페이지를 표시
- REST API 서버(Spring Boot, Django, Node.js 등)도 웹 서버의 일종

✅ **대표적인 웹 서버**: Apache, Nginx, IIS, Tomcat(웹 애플리케이션 서버)

---

### **2. 스트리밍 서버 (Streaming Server)**

✅ **역할**: 실시간 또는 점진적으로 미디어(영상, 오디오)를 클라이언트에게 제공

✅ **작동 방식**:

- **Progressive Download**: 동영상 파일을 다운로드하면서 재생 (예: HTTP 기반)
- **Real-time Streaming**: 미디어 데이터를 일정한 속도로 지속적으로 전송 (예: RTMP, HLS)✅ **사용 예시**:
- YouTube, Netflix 같은 서비스에서 동영상을 끊김 없이 재생
- 실시간 방송(Live Streaming) 제공

✅ **대표적인 스트리밍 서버**:

- **RTMP 기반**: Wowza, Red5
- **HLS 기반**: Nginx + RTMP 모듈
- **WebRTC 기반**: Kurento, Janus

---

### **📌 차이점 정리**

| 구분 | 웹 서버 | 스트리밍 서버 |
| --- | --- | --- |
| **목적** | 정적/동적 웹 콘텐츠 제공 | 오디오, 비디오 실시간 제공 |
| **프로토콜** | HTTP(S) | HTTP(HLS), RTMP, WebRTC 등 |
| **사용 예시** | 웹사이트, API 서버 | 유튜브, 넷플릭스, 라이브 방송 |
| **데이터 전송 방식** | 요청-응답 (클라이언트가 요청해야 데이터 전송) | 실시간 스트리밍 (서버가 지속적으로 전송) |

즉, **웹 서버는 파일을 요청받아 제공하는 역할**, **스트리밍 서버는 오디오/비디오를 실시간으로 전달하는 역할**을 한다. 🚀

---

### 인기도에 따른 부하 집중 및 대응

- 부하가 집중되었을 경우 어떻게 대응할 것인가?
- 매번 디스크에서 읽어서 메모리에 올릴 것인가?
- 부하 집중 시 대응 방안 → 부하를 분산시키는 것

---

## **📌 배경: 트래픽 증가와 서버 부하**

트래픽이 급격히 몰리면, 서버는 **동일한 동영상(혹은 파일)을 여러 사용자에게 동시에 제공**해야 해.

이때,

1. **매번 디스크에서 직접 파일을 읽어와서 제공할 것인지**
2. **미리 메모리(RAM)에 올려서 빠르게 제공할 것인지**이런 선택을 해야 해.

---

## **1️⃣ 매번 디스크에서 읽는 방식 (디스크 I/O 방식)**

- 사용자가 요청할 때마다 **하드디스크(HDD/SSD)에서 직접 파일을 읽어 제공**
- 초기에 서버가 따로 메모리를 차지하지 않음
- 하지만 **디스크 I/O 속도가 상대적으로 느리므로** 다수의 요청이 오면 성능 저하 발생

🔻 **단점:**

❌ 디스크 읽기 속도가 느려서 성능 저하

❌ 트래픽이 많으면 디스크 병목(I/O Bottleneck) 발생

---

## **2️⃣ 메모리에 올려서 제공하는 방식 (캐싱 방식)**

- 자주 요청되는 파일(예: 인기 동영상)을 **미리 RAM에 올려두고 제공**
- 디스크에 접근할 필요 없이 메모리에서 바로 가져오므로 훨씬 빠름
- 메모리는 용량이 한정적이므로 모든 파일을 올려두는 것은 불가능

🔹 **방법 예시:**

✅ **OS 캐싱 (파일시스템 캐시)**: 리눅스는 자주 사용하는 파일을 자동으로 캐싱

✅ **CDN (CloudFront, Cloudflare)**: 전용 캐싱 서버를 이용해 트래픽 분산

✅ **전용 캐시 서버 (Redis, Memcached)**: 자주 조회되는 데이터를 캐싱

🔺 **장점:**

✔ 디스크 I/O를 줄여서 서버 부하 감소

✔ 응답 속도가 빨라짐

🔻 **단점:**

❌ 메모리 사용량 증가 (RAM이 부족하면 캐싱 효율이 낮아짐)

❌ 모든 데이터를 캐싱할 수는 없음

---

## **📌 결론: 어떻게 해야 할까?**

1️⃣ **소규모 서비스**: 그냥 웹 서버가 알아서 처리해도 괜찮음

2️⃣ **트래픽이 많아지면?**

- **CDN 사용**: 클라이언트와 가까운 서버에서 제공
- **캐시 적용**: Redis/Memcached 활용
- **파일시스템 캐시 활용**: Nginx에서 `sendfile on;` 설정하면 OS 캐싱 사용 가능

즉, **트래픽이 많아질수록 디스크 I/O를 최소화하는 방향(캐싱, CDN, 메모리 활용)으로 가는 게 성능을 높이는 핵심**이야! 🚀

---

## **📌 로드 밸런싱이란? (Load Balancing)**

로드 밸런싱은 **여러 개의 서버(인스턴스)로 트래픽을 분산**시켜 특정 서버에 부하가 집중되지 않도록 하는 기술이야.

예를 들어,

- 갑자기 사용자가 많아지면 **하나의 서버가 감당할 수 없으므로 여러 대의 서버를 두고 트래픽을 나눠서 처리**하는 거야.
- 이를 위해 로드 밸런서(예: Nginx, AWS ELB, HAProxy)가 요청을 여러 서버로 분산시킴.

✅ **예제**

1️⃣ 사용자가 `example.com`에 접속

2️⃣ 로드 밸런서가 트래픽을 A, B, C 서버로 분배

3️⃣ 각 서버는 나눠진 요청을 처리하고 응답 반환

💡 **로드 밸런싱의 목적?**

✔ **서버 부하 분산** → 한 서버가 과부하 걸리는 것을 방지

✔ **고가용성(HA, High Availability)** → 서버 한 대가 다운되어도 다른 서버가 서비스 유지

✔ **확장성(Scalability)** → 필요하면 서버를 더 추가할 수 있음

---

## **📌 캐싱과 로드 밸런싱의 차이점**

| 구분 | 캐싱 (메모리 활용) | 로드 밸런싱 (서버 분산) |
| --- | --- | --- |
| **핵심 개념** | 자주 사용하는 데이터를 메모리에 저장하여 속도 향상 | 여러 서버로 트래픽을 나눠 부하 분산 |
| **목표** | 디스크 I/O 줄이고 응답 속도 향상 | 특정 서버에 과부하가 집중되지 않도록 함 |
| **사용 기술** | Redis, Memcached, CDN, 파일 시스템 캐시 | Nginx, AWS ELB, HAProxy |
| **적용 예시** | 동영상 파일을 미리 캐싱하여 빠르게 제공 | 대량의 API 요청을 여러 서버로 분산 |

---

## **📌 결론: 캐싱 vs 로드 밸런싱, 언제 사용해야 할까?**

✔ **트래픽이 많아서 서버가 버거워함?** → **로드 밸런싱**을 활용해서 서버 여러 대로 분산

✔ **디스크 I/O가 너무 많아 느려짐?** → **캐싱**을 활용해서 메모리에서 처리

🚀 **최적의 방법?둘 다 병행해서 사용하면 가장 효과적!**

예를 들어,

- **로드 밸런싱 + 캐싱 + CDN** 조합을 사용하면 **부하 분산 + 빠른 응답**을 동시에 해결할 수 있어.
- **대규모 서비스(유튜브, 넷플릭스 등)** 에서는 **로드 밸런서 → 캐싱 서버(REDIS, CDN) → 웹 서버** 구조를 사용함.

✅ **로드 밸런싱** → **사용자의 요청(트래픽)을 여러 서버로 분산**

✅ **캐싱** → **자주 사용하는 데이터를 미리 저장해서 빠르게 제공**

즉,

- 로드 밸런싱은 **"이 서버만 너무 바쁜데? 트래픽을 골고루 나누자!"**
- 캐싱은 **"같은 데이터를 계속 디스크에서 불러오면 느리니까, 메모리나 CDN에서 빨리 제공하자!"**

---

### 고려해야 할 주요 사항

1. 중복 접속 문제 대응
2. DRM  & 전용 플레이어 이슈
3. 라이브 스트리밍 vs 웹서버 부하 처리
4. 대규모 트래픽 대응

## 라이브 스트리밍을 서비스할 때 고려해야 할 점

- 캡쳐
- 비디오 코덱 및 인코딩
- 패키징 및 프로토콜
- 인제스트 및 트랜스 코딩
- 배포(전달)
- 재생

### 기본 구조에서 꼭 말하고 가는 포인트

- 부하 분산
- 중복 → DRM
